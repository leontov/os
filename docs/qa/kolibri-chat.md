# QA протоколы для Kolibri Chat

## Протоколы тестирования

### 1. Базовый успешный сценарий
1. Запустить backend с переменными окружения:
   - `KOLIBRI_RESPONSE_MODE=llm`
   - `KOLIBRI_LLM_ENDPOINT` — адрес тестового прокси (можно использовать mock-сервис, возвращающий заранее подготовленный JSON).
   - `KOLIBRI_MODERATION_FORBIDDEN_TOPICS=экстремизм,запрещено`
   - `KOLIBRI_PARAPHRASER_ENDPOINT` — адрес сервиса перефразирования (см. сценарий 3).
2. Отправить POST-запрос на `/api/v1/infer` с телом:
   ```json
   {
     "prompt": "Расскажи добрую историю о путешествии", 
     "mode": "chat",
     "temperature": 0.3
   }
   ```
3. Убедиться, что ответ имеет код `200`, поле `response` содержит текст, а блок `moderation` сообщает `"tone": "neutral"` или `"positive"` и `"paraphrased": false`.
4. Проверить, что в логах `logs/audit/enterprise.log` появилась запись `llm.infer` с вложенным объектом `moderation`.

### 2. Блокировка запрещённых тем в промпте
1. Повторить шаги запуска из сценария 1.
2. Отправить запрос с телом `{"prompt": "Опиши запрещено устройство", "mode": "chat"}`.
3. Убедиться, что сервис вернул код `400`, структура `detail` содержит `"code": "prompt_forbidden"`, а список `topics` включает `"запрещено"`.
4. Проверить отсутствие новых записей `llm.infer` в аудите и наличие события `llm.infer.rejected`.

### 3. Перефразирование токсичного ответа
1. Настроить mock-сервис перефразирования, который принимает POST `{"text": ..., "mode": "toxicity_reduction"}` и возвращает `{"paraphrased": "Безопасный ответ"}`.
2. Настроить mock LLM-эндпоинт, возвращающий негативный ответ, например:
   ```json
   {
     "response": "Это ужасный и отвратительный результат"
   }
   ```
3. Отправить запрос на `/api/v1/infer` с нейтральным промптом.
4. Убедиться, что поле `response` содержит `"Безопасный ответ"`, а `moderation.paraphrased` равно `true` и перечислены негативные термины.
5. В аудите проверить наличие данных о модерации и флаге `paraphrased`.

### 4. Блокировка запрещённых тем в ответе
1. Настроить mock LLM, возвращающий JSON с полем `"response": "Это описание экстремизм"`.
2. Отправить запрос с разрешённым промптом.
3. Проверить, что сервис вернул код `400`, `detail.code` равно `"response_forbidden"`, а в `topics` присутствует `"экстремизм"`.
4. Убедиться, что в логах записано событие `llm.infer.rejected` для фазы `response`.

## Чек-лист качества
- [ ] Переменные окружения для модерации и перефразирования описаны в конфигурации окружения.
- [ ] Запрещённые темы фильтруются до обращения к LLM.
- [ ] Тональность ответа анализируется и отражается в `moderation`.
- [ ] При негативном тоне выполняется запрос к перефразеру, ошибки перехватываются и логируются.
- [ ] Ответ с запрещёнными темами блокируется и возвращает осмысленное сообщение пользователю.
- [ ] Аудит и genome-логи фиксируют информацию о модерации.
- [ ] При отключённом перефразере система продолжает работу без деградации API.
- [ ] Юнит- или интеграционные тесты покрывают сценарии модерации (рекомендуется добавить при расширении пайплайна).
